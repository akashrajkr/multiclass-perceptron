{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classes.pkl', 'rb') as f:\n",
    " classes = pickle.load(f)\n",
    "with open('feature_data.pkl', 'rb') as f:\n",
    " feature_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BIAS = 1                            # Dummy Feature for use in setting constant factor in Training.\n",
    "TRAIN_TEST_RATIO = .6              # Default Ratio of data to be used in Training vs. Testing.\n",
    "ITERATIONS = 20                    # Default Number of Training Iterations.\n",
    "LR = 0.1                            # Set learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassPerceptron:\n",
    "    # Analytics values\n",
    "    precision, recall, accuracy = {}, {}, 0\n",
    "\n",
    "    \"\"\"\n",
    "    A Multi-Class Perceptron Model object, with functions for loading feature data, training the algorithm,\n",
    "    and running analytics on model performance.\n",
    "\n",
    "    :param  classes           List of categories/classes (match tags in tagged data).\n",
    "    :param  feature_data      Feature Data, in format specified in README, usually imported from feature_data module.\n",
    "    :param  train_test_ratio  Ratio of data to be used in training vs. testing. Set to 75% by default.\n",
    "    :param  iterations        Number of iterations to run training data through. Set to 100 by default.\n",
    "    \"\"\"\n",
    "    def __init__(self, classes, feature_data, train_test_ratio=TRAIN_TEST_RATIO, iterations=ITERATIONS):\n",
    "        self.classes = classes\n",
    "        self.feature_data = feature_data\n",
    "        self.ratio = train_test_ratio\n",
    "        self.iterations = iterations\n",
    "\n",
    "        # Split feature data into train set, and test set\n",
    "        random.shuffle(self.feature_data)\n",
    "        self.train_set = self.feature_data[:int(len(self.feature_data) * self.ratio)]\n",
    "        self.test_set = self.feature_data[int(len(self.feature_data) * self.ratio):]\n",
    "\n",
    "        # Initialize empty weight vectors, with extra BIAS term.\n",
    "        self.weight_vectors = {c: np.array([0.0 for _ in range(900 + 1)]) for c in self.classes}\n",
    "#         print(self.weight_vectors)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the Multi-Class Perceptron algorithm using the following method:\n",
    "\n",
    "        During each iteration of training, the data (formatted as a feature vector) is read in, and the dot\n",
    "        product is taken with each unique weight vector (which are all initially set to 0). The class that\n",
    "        yields the highest product is the class to which the data belongs. In the case this class is the\n",
    "        correct value (matches with the actual category to which the data belongs), nothing happens, and the\n",
    "        next data point is read in. However, in the case that the predicted value is wrong, the weight vectors a\n",
    "        re corrected as follows: The feature vector is subtracted from the predicted weight vector, and added to\n",
    "        the actual (correct) weight vector. This makes sense, as we want to reject the wrong answer, and accept\n",
    "        the correct one.\n",
    "        \"\"\"\n",
    "#         print('Weight before')\n",
    "#         print(self.weight_vectors)\n",
    "        for _ in range(self.iterations):\n",
    "            for category, feature_dict in self.train_set:\n",
    "                # Format feature values as a vector, with extra BIAS term.\n",
    "                img = cv2.imread(feature_dict['path'])\n",
    "                dim = (30,30)\n",
    "\n",
    "                resized = cv2.resize(img, dim, cv2.INTER_AREA)\n",
    "\n",
    "                input_array = []\n",
    "                for i in range(resized.shape[0]):\n",
    "                    for j in range(resized.shape[1]):\n",
    "                        input_array.append((np.mean(resized[i][j])/255))\n",
    "                \n",
    "                input_array.append(BIAS)\n",
    "                input_vector = np.array(input_array)\n",
    "#                 print(input_vector)\n",
    "                # Initialize arg_max value, predicted class.\n",
    "                arg_max, predicted_class = 0, self.classes[0]\n",
    "                # Multi-Class Decision Rule:\n",
    "                for c in self.classes:\n",
    "                    current_activation = np.dot(input_vector, self.weight_vectors[c])\n",
    "                    if current_activation >= arg_max:\n",
    "                        arg_max, predicted_class = current_activation, c\n",
    "                # Update Rule:\n",
    "                if not (category == predicted_class):\n",
    "                    self.weight_vectors[category] += [i*0.1 for i in input_vector]\n",
    "                    self.weight_vectors[predicted_class] -= [i*0.1 for i in input_vector]\n",
    "#         print('\\n\\nWeight After training\\n')    \n",
    "#         print(self.weight_vectors)\n",
    "\n",
    "    def predict(self, feature_dict):\n",
    "        \"\"\"\n",
    "        Categorize a brand-new, unseen data point based on the existing collected data.\n",
    "\n",
    "        :param  feature_dict        Dictionary of the same form as the training feature data.\n",
    "        :return                     Return the predicted category for the data point.\n",
    "        \"\"\"\n",
    "        img = cv2.imread(feature_dict['path'])\n",
    "        dim = (30,30)\n",
    "\n",
    "        resized = cv2.resize(img, dim, cv2.INTER_AREA)\n",
    "\n",
    "        input_array = []\n",
    "        for i in range(resized.shape[0]):\n",
    "            for j in range(resized.shape[1]):\n",
    "                input_array.append((np.mean(resized[i][j])/255))\n",
    "\n",
    "        input_array.append(BIAS)\n",
    "        feature_vector = np.array(input_array)\n",
    "\n",
    "        # Initialize arg_max value, predicted class.\n",
    "        arg_max, predicted_class = 0, self.classes[0]\n",
    "\n",
    "        # Multi-Class Decision Rule:\n",
    "        for c in self.classes:\n",
    "            current_activation = np.dot(feature_vector, self.weight_vectors[c])\n",
    "            if current_activation >= arg_max:\n",
    "                arg_max, predicted_class = current_activation, c\n",
    "\n",
    "        return predicted_class\n",
    "    \n",
    "    def test_random(self):\n",
    "        item = random.choice(self.test_set)\n",
    "        print(\"Actual class: \" + item[0])\n",
    "        pred_class = self.predict(item[1])\n",
    "        print(\"Perdicted class: \"+ pred_class)\n",
    "    \n",
    "    def run_analytics(self):\n",
    "        \"\"\"\n",
    "        Runs analytics on the classifier, returning data on precision, recall, accuracy.\n",
    "\n",
    "        :return: Prints statistics to screen.\n",
    "        \"\"\"\n",
    "        print (\"CLASSIFIER ANALYSIS: \")\n",
    "        print (\"\")\n",
    "        self.calculate_precision()\n",
    "        print (\"\")\n",
    "        self.calculate_recall()\n",
    "        print (\"\")\n",
    "        self.calculate_accuracy()\n",
    "\n",
    "    def calculate_precision(self):\n",
    "        \"\"\"\n",
    "        Calculates the precision of the classifier by running algorithm against test set and comparing\n",
    "        the output to the actual categorization.\n",
    "        \"\"\"\n",
    "        test_classes = [f[0] for f in self.test_set]\n",
    "        correct_counts = {c: 0 for c in test_classes}\n",
    "        total_counts = {c: 0 for c in test_classes}\n",
    "        for feature_dict in self.test_set:\n",
    "            actual_class = feature_dict[0]\n",
    "            predicted_class = self.predict(feature_dict[1])\n",
    "\n",
    "            if actual_class == predicted_class:\n",
    "                correct_counts[actual_class] += 1\n",
    "                total_counts[actual_class] += 1\n",
    "            else:\n",
    "                total_counts[predicted_class] += 1\n",
    "                \n",
    "        print (\"PRECISION STATISTICS:\")\n",
    "\n",
    "        for c in correct_counts:\n",
    "            if not (correct_counts[c] == 0):\n",
    "                self.precision[c] = (correct_counts[c] * 1.0) / (total_counts[c] * 1.0)\n",
    "                print (\"%s Class Precision:\" % (c.upper()), self.precision[c])\n",
    "            else:\n",
    "                print (\"%s Class Precision:\" % (c.upper()), 0)\n",
    "\n",
    "    def calculate_recall(self):\n",
    "        \"\"\"\n",
    "        Calculates the recall of the classifier by running algorithm against test set and comparing\n",
    "        the output to the actual categorization.\n",
    "        \"\"\"\n",
    "        test_classes = [f[0] for f in self.test_set]\n",
    "        \n",
    "        correct_counts = {c: 0 for c in test_classes}\n",
    "        total_counts = {c: 0 for c in test_classes}\n",
    "\n",
    "        for feature_dict in self.test_set:\n",
    "            actual_class = feature_dict[0]\n",
    "            predicted_class = self.predict(feature_dict[1])\n",
    "\n",
    "            if actual_class == predicted_class:\n",
    "                correct_counts[actual_class] += 1\n",
    "                total_counts[actual_class] += 1\n",
    "            else:\n",
    "                total_counts[actual_class] += 1\n",
    "\n",
    "        print (\"RECALL STATISTICS:\")\n",
    "\n",
    "        for c in correct_counts:\n",
    "            self.recall[c] = (correct_counts[c] * 1.0) / (total_counts[c] * 1.0)\n",
    "            print (\"%s Class Recall:\" % (c.upper()), self.recall[c])\n",
    "\n",
    "    def calculate_accuracy(self):\n",
    "        \"\"\"\n",
    "        Calculates the accuracy of the classifier by running algorithm against test set and comparing\n",
    "        the output to the actual categorization.\n",
    "        \"\"\"\n",
    "        correct, incorrect = 0, 0\n",
    "        random.shuffle(self.feature_data)\n",
    "        self.test_set = self.feature_data[int(len(self.feature_data) * self.ratio):]\n",
    "        for feature_dict in self.test_set:\n",
    "            actual_class = feature_dict[0]\n",
    "            predicted_class = self.predict(feature_dict[1])\n",
    "\n",
    "            if actual_class == predicted_class:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect += 1\n",
    "\n",
    "        print (\"ACCURACY:\")\n",
    "        print (\"Model Accuracy:\", (correct * 1.0) / ((correct + incorrect) * 1.0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Sandbox Script to demonstrate entire Pipeline (Loading, Training, Saving, getting Analytics)\n",
    "if __name__ == \"__main__\":\n",
    "    classifier = MultiClassPerceptron(classes,feature_data)\n",
    "    classifier.train()\n",
    "    classifier.calculate_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
